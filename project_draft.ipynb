{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a53177-8cae-44ea-9297-9ff8cb808b39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Project Title\n",
    "\n",
    "- Leslie Cohrt: put their contribution here\n",
    "- Sarah Auther: put their contribution here\n",
    "- Shoshana Medved: put their contribution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07035b74-71fd-4344-8bb4-566529eb7cb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Introduction\n",
    "\n",
    "blah blah blah blah blah AI becoming more common, free to use, etc, people are developing a relationship with it, idk\n",
    "\n",
    "- How have people's opinions of ChatGPT evolved as its usage has become more normalized?\n",
    "- What generates the most reaction between real people when talking about ChatGPT?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3a809-0978-4168-8de5-f6038fb446f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Detailed description of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3635854-89b7-4904-9fb8-d9e0be7e2d73",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>country</th>\n",
       "      <th>photo_url</th>\n",
       "      <th>city</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.598010e+18</td>\n",
       "      <td>2022-11-30 18:00:15+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.598010e+18</td>\n",
       "      <td>2022-11-30 18:02:06+00:00</td>\n",
       "      <td>12179</td>\n",
       "      <td>889</td>\n",
       "      <td>1130</td>\n",
       "      <td>3252</td>\n",
       "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.598010e+18</td>\n",
       "      <td>2022-11-30 18:02:58+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/media/Fi1J8HbWAAMv_yi.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.598020e+18</td>\n",
       "      <td>2022-11-30 18:05:58+00:00</td>\n",
       "      <td>561</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/media/Fi1Km3WUYAAfzHS.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.598020e+18</td>\n",
       "      <td>2022-11-30 18:06:01+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id                 created_at  like_count  quote_count  \\\n",
       "0  1.598010e+18  2022-11-30 18:00:15+00:00           2            0   \n",
       "1  1.598010e+18  2022-11-30 18:02:06+00:00       12179          889   \n",
       "2  1.598010e+18  2022-11-30 18:02:58+00:00           2            0   \n",
       "3  1.598020e+18  2022-11-30 18:05:58+00:00         561            8   \n",
       "4  1.598020e+18  2022-11-30 18:06:01+00:00           1            0   \n",
       "\n",
       "   reply_count  retweet_count  \\\n",
       "0            0              0   \n",
       "1         1130           3252   \n",
       "2            0              1   \n",
       "3           25             66   \n",
       "4            0              0   \n",
       "\n",
       "                                               tweet country  \\\n",
       "0  ChatGPT: Optimizing Language Models for Dialog...     NaN   \n",
       "1  Try talking with ChatGPT, our new AI system wh...     NaN   \n",
       "2  ChatGPT: Optimizing Language Models for Dialog...     NaN   \n",
       "3  THRILLED to share that ChatGPT, our new model ...     NaN   \n",
       "4  As of 2 minutes ago, @OpenAI released their ne...     NaN   \n",
       "\n",
       "                                         photo_url city country_code  \n",
       "0                                              NaN  NaN          NaN  \n",
       "1                                              NaN  NaN          NaN  \n",
       "2  https://pbs.twimg.com/media/Fi1J8HbWAAMv_yi.jpg  NaN          NaN  \n",
       "3  https://pbs.twimg.com/media/Fi1Km3WUYAAfzHS.jpg  NaN          NaN  \n",
       "4                                              NaN  NaN          NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"chatgpt.data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f69b2d72-2852-41ee-b792-14e6b8b87e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.201360e+05</td>\n",
       "      <td>120136.000000</td>\n",
       "      <td>120136.000000</td>\n",
       "      <td>120136.000000</td>\n",
       "      <td>120136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.602453e+18</td>\n",
       "      <td>30.716463</td>\n",
       "      <td>0.716072</td>\n",
       "      <td>2.120688</td>\n",
       "      <td>4.155083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.985152e+15</td>\n",
       "      <td>658.769995</td>\n",
       "      <td>19.037848</td>\n",
       "      <td>34.355344</td>\n",
       "      <td>85.684421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.598010e+18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.600020e+18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.601650e+18</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.604640e+18</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.609340e+18</td>\n",
       "      <td>119321.000000</td>\n",
       "      <td>4598.000000</td>\n",
       "      <td>5184.000000</td>\n",
       "      <td>10593.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id     like_count    quote_count    reply_count  \\\n",
       "count  1.201360e+05  120136.000000  120136.000000  120136.000000   \n",
       "mean   1.602453e+18      30.716463       0.716072       2.120688   \n",
       "std    2.985152e+15     658.769995      19.037848      34.355344   \n",
       "min    1.598010e+18       1.000000       0.000000       0.000000   \n",
       "25%    1.600020e+18       1.000000       0.000000       0.000000   \n",
       "50%    1.601650e+18       2.000000       0.000000       0.000000   \n",
       "75%    1.604640e+18       6.000000       0.000000       1.000000   \n",
       "max    1.609340e+18  119321.000000    4598.000000    5184.000000   \n",
       "\n",
       "       retweet_count  \n",
       "count  120136.000000  \n",
       "mean        4.155083  \n",
       "std        85.684421  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max     10593.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df1 = df.fillna(value=0)\n",
    "df1 = df1.loc[df1[\"like_count\"] != 0]\n",
    "\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcbd9f8-9f78-44d8-b302-56ccc0b231a2",
   "metadata": {},
   "source": [
    "Our research questions are about shared public opinion and about opinions that generate conversation and response. Tweets with no likes are not indicative of opinions shared by many and do not generate response, so we removed them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "088888d5-0a2f-4d0d-928e-93ba50e46c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.5.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.10/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (4.65.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (8.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "!pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71af7cf8-6db8-4cbb-ad0e-1ccc51aceaed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Word tokenization    \n",
    "text = df1['tweet'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa0f8610-c051-404a-bc54-27b6575c7b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [ChatGPT, :, Optimizing, Language, Models, for...\n",
      "1         [Try, talking, with, ChatGPT, ,, our, new, AI,...\n",
      "2         [ChatGPT, :, Optimizing, Language, Models, for...\n",
      "3         [THRILLED, to, share, that, ChatGPT, ,, our, n...\n",
      "4         [As, of, 2, minutes, ago, ,, @, OpenAI, releas...\n",
      "                                ...                        \n",
      "219287    [One, of, my, new, favorite, thing, to, do, wi...\n",
      "219288    [Sounds, like, AI, ca, n't, predict, 2023, tre...\n",
      "219290    [I, asked, #, ChatGPT, to, write, a, #, NYE, J...\n",
      "219291    [chatgpt, is, being, disassembled, until, it, ...\n",
      "219292    [2023, predictions, by, #, chatGPT, ., Nothing...\n",
      "Name: tweet, Length: 120136, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "548276e3-2eb0-476c-9747-bf4f5f46917a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c6a6fba-84cb-471f-a744-474efc61e363",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'which', 'some', 'wouldn', \"it's\", \"isn't\", \"weren't\", 'isn', 'she', 'that', 'or', \"didn't\", 'i', \"shouldn't\", 'these', 'we', 'the', 'at', 'now', 'll', 'on', 'again', 'below', 'you', 'few', 'yours', 'himself', 'weren', 'themselves', 'd', 'whom', \"doesn't\", 'here', \"wasn't\", 'who', 'haven', 'o', \"don't\", 'a', 'out', 'our', \"should've\", 'be', 'no', 'against', 'after', 'how', 'they', 'hers', \"aren't\", 'those', \"you'll\", 'because', 'about', 'myself', 'same', 'for', 'up', \"hadn't\", \"you'd\", 'by', 'before', 'can', 'yourself', \"that'll\", 'shouldn', 'just', 'didn', \"shan't\", 'my', 'should', 'needn', \"you've\", 'couldn', 'mightn', 'its', 'your', 'his', 'doing', 'to', 'both', 'will', 'don', 'this', 'once', 'me', 'such', \"mustn't\", 'until', 'has', 'do', 'their', 'if', 'does', 'own', 'each', 're', 'there', 'aren', 'was', 'very', 'an', 'not', \"wouldn't\", 'them', 'only', 'ourselves', 'in', 'm', 'more', \"hasn't\", 'then', 'ours', 'him', 'mustn', 'under', 'shan', 'and', 'with', 'did', 't', 'all', \"you're\", \"won't\", \"haven't\", 'being', 'herself', 'into', 'been', 'than', 'it', 'from', 've', 'hasn', \"needn't\", 'itself', 'other', 'so', 'doesn', 'further', 's', 'am', 'had', 'are', 'why', 'nor', \"she's\", 'during', 'too', 'wasn', 'most', 'y', 'her', 'while', 'theirs', 'as', 'any', 'is', 'over', \"mightn't\", 'he', \"couldn't\", 'yourselves', 'ain', 'hadn', 'where', 'down', 'between', 'have', 'having', 'what', 'won', 'were', 'above', 'through', 'but', 'ma', 'off', 'of', 'when'}\n",
      "{'>', '\"', '\\\\', '#', '-', '}', ';', '*', '^', '<', '`', \"'\", '?', '$', '@', '/', ',', '[', '=', '_', '!', ')', '+', '{', '|', '.', '%', ':', ']', '~', '(', '&'}\n"
     ]
    }
   ],
   "source": [
    "exclude = set(string.punctuation)\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "print(stop)\n",
    "print(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39688a03-a664-4d4c-88b6-12841b146969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_tokens = []\n",
    "for token in text:\n",
    "    for word in token:\n",
    "        if word.lower() not in exclude:\n",
    "            if word.lower() not in stop:\n",
    "                filtered_tokens.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "941dbe3f-449a-47a7-b995-904c45823107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd73e18-e17e-4eee-8d60-43fe80999091",
   "metadata": {},
   "source": [
    "#### How have people's opinions of ChatGPT evolved as its usage has become more normalized?\n",
    "- sentiment analysis\n",
    "- dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b472ac5b-fad0-414d-a2bc-7733323a2f3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### What generates the most reaction between real people when talking about ChatGPT?\n",
    "- sentiment analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
